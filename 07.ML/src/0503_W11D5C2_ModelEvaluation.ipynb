{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 모델 평가하는 방법론 \n",
    "\n",
    "회귀 모델은 실제값과 에러치로 계산한다. \\\n",
    "레드와인과 화이트와인 분류 모델을 통해 \n",
    "다양한 판단 방법을 알아보고 ROC 곡선을 통해 성능을 비교해본다.\n",
    "\n",
    "|이름|의미|\n",
    "|:----|:----|\n",
    "|Accuracy| 전체 데이터 중 맞게 예측한 비율|\n",
    "|Precision| 참이라고 예측한 것 중 참인 비율|\n",
    "|Recall| 참인 데이터 중 참이라고 예측한 비율|\n",
    "|Fall-out| 거짓인데 참이라고 예측한 비율|\n",
    "|F1-score| Precision과 Recall의 조화평균이 높은 값|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_url = 'https://raw.githubusercontent.com/PinkWink/forML_study_data/main/data/winequality-red.csv'\n",
    "white_url = 'https://raw.githubusercontent.com/PinkWink/forML_study_data/main/data/winequality-white.csv'\n",
    "\n",
    "red_wine = pd.read_csv(red_url, sep=';')\n",
    "white_wine = pd.read_csv(white_url, sep=';')\n",
    "red_wine['color']=1.\n",
    "white_wine['color']=0.\n",
    "wine = pd.concat([red_wine, white_wine])\n",
    "wine['taste'] = [1. if grade > 5 else 0. for grade in wine['quality']]\n",
    "x = wine.drop(['taste', 'quality'], axis=1)\n",
    "y = wine['taste']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=5)\n",
    "wine_tree = DecisionTreeClassifier(max_depth=4, random_state=5)\n",
    "wine_tree.fit(x_train, y_train)\n",
    "y_pred_tr = wine_tree.predict(x_train)\n",
    "y_pred_test = wine_tree.predict(x_test)\n",
    "print('Train Acc    : ', accuracy_score(y_train, y_pred_tr))\n",
    "print('Test Acc     : ', accuracy_score(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy          : 전체 데이터 중 맞게 예측한 비율\n",
    "# Precision         : 참이라고 예측한 것 중 참인 비율\n",
    "# Recall            : 참인 데이터 중 참이라고 예측한 비율\n",
    "# Fall-out          : 거짓인데 참이라고 예측한 비율\n",
    "# F1-score          : Precision과 Recall의 조화평균이 높은 값\n",
    "\n",
    "print('Accuarcy     : ', accuracy_score(y_test, y_pred_test))\n",
    "print('Recall       : ', recall_score(y_test, y_pred_test))\n",
    "print('Precision    : ', precision_score(y_test, y_pred_test))\n",
    "print('AUC score    : ', roc_auc_score(y_test, y_pred_test))\n",
    "print('F1 score     : ', f1_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC 곡선, TPR(y)은 Recall, FPR(x)는 Fall-out을 의미한다.\n",
    "# 직선에 가까울 수록 모델의 성능이 떨어지는 것으로 판단.\n",
    "\n",
    "pred_proba = wine_tree.predict_proba(x_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, pred_proba)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot([0,1], [0,1])\n",
    "plt.plot(fpr, tpr)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openCV_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
