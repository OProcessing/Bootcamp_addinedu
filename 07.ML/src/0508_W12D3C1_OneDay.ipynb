{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly_express as px\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Sklearn을 이용해서 iris 데이터를 읽어서 pandas dataframe에 저장한 결과를 캡쳐해서 올려주세요\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['target'] = iris.target\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Plotly express를 이용해서 네 개의 특성을 한 그래프에 boxplot으로 그린 결과를 캡쳐해서 올려주세요\n",
    "\n",
    "fig = px.box(iris_df.iloc[:,:4])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Standard Scaler를 적용한 데이터를 또 다른 pandas dataframe에 저장한 결과를 캡쳐해서 올려주세요\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_ss = ss.fit_transform(iris_df)\n",
    "iris_ss = pd.DataFrame(iris_ss, columns=iris.feature_names)\n",
    "iris_ss['target'] = iris.target\n",
    "iris_ss.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Standard Scaler를 적용한 데이터의 네 개의 특성을 한 그래프에 boxplot을 그려주세요. 이때 plotly express를 사용해주세요. 그리고 결과를 캡쳐해서 올려주세요\n",
    "\n",
    "fig = px.box(iris_ss.iloc[:,:4])\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Standard Scaler를 적용한 데이터를 8:2로 train, test 데이터로 나눈 결과를 캡쳐해서 올려주세요\n",
    "\n",
    "x = iris_ss.iloc[:,:4]\n",
    "y = iris_ss['target']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=5, stratify=y)\n",
    "print(len(x_train),',',len(x_test),',',len(y_train),',',len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 5번의 train 데이터에 RandomForestClassifier, DecisionTreeClassifier, LogisticRegression, kNN 모델들을 이용해서 분류학습을 시켜주세요.\n",
    "# 이때 각각의 모델의 test 데이터에 대한 accuracy를 제시해 주세요. 하이퍼파라미터는 알아서 잡아주세요. 그리고 결과를 캡쳐해서 올려주세요\n",
    "\n",
    "x = iris_ss.drop(['target'],axis=1)\n",
    "y = iris_ss['target']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=50, stratify=y)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=50, n_estimators=100)\n",
    "rf.fit(x_train, y_train)\n",
    "iris_rf = rf.predict(x_test)\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=2, random_state=50)\n",
    "tree.fit(x_train, y_train)\n",
    "iris_tree = tree.predict(x_test)\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear', random_state=50)\n",
    "lr.fit(x_train, y_train)\n",
    "iris_lr = lr.predict(x_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x_train, y_train)\n",
    "iris_knn = knn.predict(x_test)\n",
    "\n",
    "print(\"RandomForest Score       :\", accuracy_score(iris_rf, y_test))\n",
    "print('DecisionTree Score       :', accuracy_score(y_test, iris_tree))\n",
    "print('LogisticRegression Score :', accuracy_score(y_test, iris_lr))\n",
    "print('KNeighbors Score         :', accuracy_score(y_test,iris_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 6번의 상황에서 train 데이터와 test 데이터의 accuracy를 모델별로 pandas dataframe에 정리해 주시고, 결과를 캡쳐해서 올려주세요\n",
    "\n",
    "x = iris_ss.drop(['target'],axis=1)\n",
    "y = iris_ss['target']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=50)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=5, n_estimators=100)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=2, random_state=5)\n",
    "tree.fit(x_train, y_train)\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear', random_state=5)\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "scores_df = []\n",
    "train_df = []\n",
    "test_df = []\n",
    "\n",
    "train_df.append(accuracy_score(y_train, rf.predict(x_train)))\n",
    "train_df.append(accuracy_score(y_train, tree.predict(x_train)))\n",
    "train_df.append(accuracy_score(y_train, lr.predict(x_train)))\n",
    "train_df.append(accuracy_score(y_train, knn.predict(x_train)))\n",
    "\n",
    "test_df.append(accuracy_score(y_test, rf.predict(x_test)))\n",
    "test_df.append(accuracy_score(y_test, tree.predict(x_test)))\n",
    "test_df.append(accuracy_score(y_test, lr.predict(x_test)))\n",
    "test_df.append(accuracy_score(y_test, knn.predict(x_test)))\n",
    "\n",
    "scores_df.append(train_df)\n",
    "scores_df.append(test_df)\n",
    "\n",
    "scores_df = pd.DataFrame(scores_df, columns=['RandomForest', 'DecisionTree', 'LogisticRegression', 'KNeighbors'])\n",
    "scores_df.index = ['Train', 'Test']\n",
    "\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. 6번의 상황에서 5겹 kFold해서 cross validation score를 계산해서, 각 모델별로 각 score의 평균과 표준편차를 제시해 주시고, 결과를 캡쳐해서 올려주세요.\n",
    "\n",
    "x = iris_ss.drop(['target'],axis=1)\n",
    "y = iris_ss['target']\n",
    "\n",
    "rf = RandomForestClassifier(random_state=5, n_estimators=100)\n",
    "tree = DecisionTreeClassifier(max_depth=2, random_state=5)\n",
    "lr = LogisticRegression(solver='liblinear', random_state=5)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "scores_rf = cross_val_score(rf, x, y, scoring=None, cv=kfold)\n",
    "scores_tree = cross_val_score(tree, x, y, scoring=None, cv=kfold)\n",
    "scores_lr = cross_val_score(lr, x, y, scoring=None, cv=kfold)\n",
    "scores_knn = cross_val_score(knn, x, y, scoring=None, cv=kfold)\n",
    "\n",
    "scores_list = []\n",
    "scores_list.append(list(scores_rf))\n",
    "scores_list.append(list(scores_tree))\n",
    "scores_list.append(list(scores_lr))\n",
    "scores_list.append(list(scores_knn))\n",
    "scores_df = pd.DataFrame(scores_list, index=['Random Forest', 'Decision Tree', 'Logistic Regression', 'K-Nearest Neighbors'])\n",
    "scores_df.columns = [f'Fold {i+1}' for i in range(5)] \n",
    "mean_scores = scores_df.mean(axis=1)\n",
    "std_scores = scores_df.std(axis=1)\n",
    "scores_df['Mean'] = mean_scores\n",
    "scores_df['Std'] = std_scores\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. 8번의 상황에서 각 모델별 cv score를 boxplot으로 그려서 비교해주세요. 여러분들은 어떤 모델이 가장 좋다고 생각하나요? 간단히 적어주세요.\n",
    "\n",
    "transpose_df = np.transpose(scores_df)\n",
    "fig = px.box(transpose_df.iloc[0:5])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. 9번의 상황에서 각 fold별 score를 모델별로 pandas dataframe에 정리한 결과를 캡쳐해서 올려주세요\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. 다시 원본 데이터에서 데이터를 test와 train으로 나눈 후, Standard scaler와 Decision Tree를 연달아 사용하는 pipeline을 꾸며 주세요.\n",
    "# 그리고, 해당 pipeline을 cross validation을 수행해서 score를 캡쳐로 제시해 주세요.\n",
    "\n",
    "x = iris_df\n",
    "y = iris.target\n",
    "\n",
    "estimators = [('scaler', StandardScaler()), ('clf', DecisionTreeClassifier(max_depth=2, random_state=50))]\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "scores_rf = cross_validate(pipe, x, y, scoring='accuracy', cv=5)\n",
    "scores_rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. 11번의 상황에서 6번의 모델들을 모두 pipeline에 각각 적용해 주세요. 그리고 해당 pipeline을 cross validation을 수행해서 score를 캡쳐로 제시해 주세요.\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['target'] = iris.target\n",
    "\n",
    "x = iris_df.drop(['target'], axis=1)\n",
    "y = iris_df['target']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=50)\n",
    "\n",
    "pipe_rf = Pipeline([('scaler', StandardScaler()), ('clf', RandomForestClassifier(random_state=50, n_estimators=100))])\n",
    "pipe_tree = Pipeline([('scaler', StandardScaler()), ('clf', DecisionTreeClassifier(max_depth=2, random_state=50))])\n",
    "pipe_lr = Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression(solver='liblinear', random_state=50))])\n",
    "pipe_knn = Pipeline([('scaler', StandardScaler()), ('clf', KNeighborsClassifier(n_neighbors=5))])\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "scores_rf = cross_validate(pipe_rf, x, y, scoring='accuracy', cv=5)\n",
    "scores_tree = cross_validate(pipe_tree, x, y, scoring='accuracy', cv=5)\n",
    "scores_lr = cross_validate(pipe_lr, x, y, scoring='accuracy', cv=5)\n",
    "scores_knn = cross_validate(pipe_knn, x, y, scoring='accuracy', cv=5)\n",
    "\n",
    "scores_list = []\n",
    "scores_list.append(scores_rf['test_score'])\n",
    "scores_list.append(scores_tree['test_score'])\n",
    "scores_list.append(scores_lr['test_score'])\n",
    "scores_list.append(scores_knn['test_score'])\n",
    "\n",
    "scores_df = pd.DataFrame(scores_list, index=['Random Forest', 'Decision Tree', 'Logistic Regression', 'K-Nearest Neighbors'])\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Pipeline에 분류기를 DecisionTree와 RandomForest, kNN을 적용한 후 GridSearchCV를 통해 최적의 모델과 파라미터를 찾아주세요. 그리고 결과를 캡쳐해서 올려주세요\n",
    "\n",
    "iris_df['target'] = iris.target\n",
    "x = iris_df.drop(['target'], axis=1)\n",
    "y = iris_df['target']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=50)\n",
    "\n",
    "pipe_rf = Pipeline([('scaler', StandardScaler()), ('clf', RandomForestClassifier())])\n",
    "pipe_tree = Pipeline([('scaler', StandardScaler()), ('clf', DecisionTreeClassifier())])\n",
    "pipe_knn = Pipeline([('scaler', StandardScaler()), ('clf', KNeighborsClassifier())])\n",
    "\n",
    "param_grid_rf = {\n",
    "    'clf__max_depth': [2, 5, 10, 15, 20],\n",
    "    'clf__n_estimators': [50, 100, 200],\n",
    "    'clf__min_samples_split': [6, 8, 12],\n",
    "    'clf__min_samples_leaf': [6, 8, 12],\n",
    "}\n",
    "param_grid_tree = {\n",
    "    'clf__criterion': ['gini', 'entropy'],\n",
    "    'clf__max_depth': [2, 5, 10, 15, 20],\n",
    "    'clf__min_samples_split': [6, 8, 12],\n",
    "    'clf__min_samples_leaf': [6, 8, 12],\n",
    "}\n",
    "param_grid_knn = {\n",
    "    'clf__n_neighbors': [3, 5, 7, 9],\n",
    "    'clf__weights': ['uniform', 'distance'],\n",
    "    'clf__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "params = {'max_depth':list(range(6,18,2))}\n",
    "grid_rf = GridSearchCV(pipe_rf, param_grid=param_grid_rf, scoring='accuracy', cv=5, return_train_score=True)\n",
    "grid_rf.fit(x_train, y_train)\n",
    "grid_tree = GridSearchCV(pipe_tree, param_grid=param_grid_tree, scoring='accuracy', cv=5, return_train_score=True)\n",
    "grid_tree.fit(x_train, y_train)\n",
    "grid_knn = GridSearchCV(pipe_knn, param_grid=param_grid_knn, scoring='accuracy', cv=5, return_train_score=True)\n",
    "grid_knn.fit(x_train, y_train)\n",
    "\n",
    "best_rf_estimator = grid_rf.best_estimator_\n",
    "best_tree_estimator = grid_tree.best_estimator_\n",
    "best_knn_estimator = grid_knn.best_estimator_\n",
    "\n",
    "accuracy_grid_rf = accuracy_score(y_test, best_rf_estimator.predict(x_test))\n",
    "accuracy_grid_tree = accuracy_score(y_test, best_tree_estimator.predict(x_test))\n",
    "accuracy_grid_knn = accuracy_score(y_test, best_knn_estimator.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_rf_estimator, accuracy_grid_rf)\n",
    "print(best_tree_estimator, accuracy_grid_tree)\n",
    "print(best_knn_estimator, accuracy_grid_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openCV_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
